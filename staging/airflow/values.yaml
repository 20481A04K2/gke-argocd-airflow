airflow:
  # 1. Disable internal DB/Redis
  postgresql:
    enabled: false
  redis:
    enabled: false

  # 2. Database Connection
  data:
    metadataSecretName: "airflow-db-secrets"

  # 3. Component Configs
  executor: "KubernetesExecutor"
  
  images:
    airflow:
      repository: "apache/airflow"
      tag: "2.10.0"

  # ---------------------------------------------------------
  # RESOURCE OPTIMIZATION
  # ---------------------------------------------------------
  webserver:
    resources:
      requests:
        cpu: "100m"
        memory: "256Mi"
    podAnnotations:
      gke-gcsfuse/volumes: "true"
    extraVolumes:
      - name: gcs-dags
        csi:
          driver: gcsfuse.csi.storage.gke.io
          volumeAttributes:
            bucketName: "dag-bucket213"
    extraVolumeMounts:
      - name: gcs-dags
        mountPath: /opt/airflow/dags
    extraContainers:
      - name: cloud-sql-proxy
        image: gcr.io/cloud-sql-connectors/cloud-sql-proxy:2.11.0
        args: ["--port=5432", "gcp-another-pro:us-east4:vamsi"]
    waitForMigrations:
      enabled: false
    service:
      type: LoadBalancer
      annotations:
        networking.gke.io/load-balancer-type: "Internal"
      ports:
        - name: airflow-ui
          port: 8080

  scheduler:
    resources:
      requests:
        cpu: "100m"
        memory: "256Mi"
    podAnnotations:
      gke-gcsfuse/volumes: "true"
    extraVolumes:
      - name: gcs-dags
        csi:
          driver: gcsfuse.csi.storage.gke.io
          volumeAttributes:
            bucketName: "dag-bucket213"
    extraVolumeMounts:
      - name: gcs-dags
        mountPath: /opt/airflow/dags
    extraContainers:
      - name: cloud-sql-proxy
        image: gcr.io/cloud-sql-connectors/cloud-sql-proxy:2.11.0
        args: ["--port=5432", "gcp-another-pro:us-east4:vamsi"]
    waitForMigrations:
      enabled: false

  statsd:
    resources:
      requests:
        cpu: "50m"
        memory: "128Mi"

  triggerer:
    resources:
      requests:
        cpu: "50m"
        memory: "128Mi"

  workers:
    resources:
      requests:
        cpu: "100m"
        memory: "256Mi"
    podAnnotations:
      gke-gcsfuse/volumes: "true"
    extraVolumes:
      - name: gcs-dags
        csi:
          driver: gcsfuse.csi.storage.gke.io
          volumeAttributes:
            bucketName: "dag-bucket213"
    extraVolumeMounts:
      - name: gcs-dags
        mountPath: /opt/airflow/dags

  # ---------------------------------------------------------
  # 4. FIXED JOBS (Added Cloud SQL Proxy)
  # ---------------------------------------------------------
  migrateDatabaseJob:
    useHelmHooks: false
    resources:
      requests:
        cpu: "50m"
        memory: "128Mi"
    extraContainers:
      - name: cloud-sql-proxy
        image: gcr.io/cloud-sql-connectors/cloud-sql-proxy:2.11.0
        args: ["--port=5432", "gcp-another-pro:us-east4:vamsi"]
        securityContext:
          runAsNonRoot: true

  createUserJob:
    useHelmHooks: false
    resources:
      requests:
        cpu: "50m"
        memory: "128Mi"
    extraContainers:
      - name: cloud-sql-proxy
        image: gcr.io/cloud-sql-connectors/cloud-sql-proxy:2.11.0
        args: ["--port=5432", "gcp-another-pro:us-east4:vamsi"]
        securityContext:
          runAsNonRoot: true

  # 5. DAG Storage
  dags:
    gitSync:
      enabled: false
    persistence:
      enabled: false

  # 6. Workload Identity & RBAC
  rbac:
    create: true
  serviceAccount:
    create: true
    annotations:
      iam.gke.io/gcp-service-account: "airflow-gsa@gcp-another-pro.iam.gserviceaccount.com"

  # 7. LOG STORAGE
  logs:
    persistence:
      enabled: false 
  config:
    core:
      load_examples: "False"
      dags_folder: "/opt/airflow/dags"
